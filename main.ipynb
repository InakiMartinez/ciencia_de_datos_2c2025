{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b889250f",
   "metadata": {},
   "source": [
    "# Primer Parcial\n",
    "\n",
    "#### 01-4900 | 2C 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4febd0f6",
   "metadata": {},
   "source": [
    "*Alumnos* :\n",
    "*   MARTINEZ CANNELLA, IÑAKI\n",
    "*   GHIANO, GONZALO AGUSTÍN\n",
    "*   CHAILE, FACUNDO MARTIN\n",
    "*   ALAZRAKI, MICAELA AGUSTINA\n",
    "*   RINAUDO, DIEGO NAHUEL\n",
    "\n",
    "*Grupo* :\n",
    "Data y Familia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84354b60",
   "metadata": {},
   "source": [
    "## Enunciado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee93d17e",
   "metadata": {},
   "source": [
    "La empresa “Business Prop SRL” contrata nuestros servicios para que le desarrollemos un\n",
    "modelo que permita predecir si los departamentos vendidos pagan o no comisión, cuando su\n",
    "precio de venta sea superior a un determinado valor.\n",
    "Para ello, nos comparten un dataset llamado dptos_entrenamiento.csv, que contiene\n",
    "información de departamentos vendidos en distintos lugares de Argentina y el exterior. Este\n",
    "dataset será el que utilicemos para el entrenamiento del modelo construido.\n",
    "El dataset de predicción a utilizar es dptos_predecir.csv, el cual no contiene la etiqueta de la\n",
    "variable clase (por defecto viene indicada como “no paga”)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc93d3d",
   "metadata": {},
   "source": [
    "## Solución"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d186fa",
   "metadata": {},
   "source": [
    "### Carga de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2414099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Agregamos modelos de ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e21e61",
   "metadata": {},
   "source": [
    "### Lectura de los dataset\n",
    "\n",
    "Cargamos los DataSets, que se encuentran en formato CSV, para poder armar los DataFrames correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec160d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardamos las url en variables\n",
    "url_train = 'https://raw.githubusercontent.com/pokengineer/DataScience/refs/heads/main/assessment/dptos_entrenamiento.csv'\n",
    "url_test = 'https://raw.githubusercontent.com/pokengineer/DataScience/refs/heads/main/assessment/dptos_predecir.csv'\n",
    "\n",
    "# leemos los datos\n",
    "df_train = pd.read_csv(url_train)\n",
    "df_test = pd.read_csv(url_test)\n",
    "\n",
    "# mostramos para tener una idea de como se ven los datos\n",
    "print(\"Datos de Entrenamiento:\", df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f77ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Datos de Test:\", df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9140c780",
   "metadata": {},
   "source": [
    "### Análisis Exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf3faa2",
   "metadata": {},
   "source": [
    "#### Variables categóricas y numéricas\n",
    "\n",
    "Entendemos los datos antes de intentar modelar:\n",
    "* Buscamos estadísticas generales para detectar diferencias entre variables con escalas distintas, columnas con valores faltantes, repetidos o sin variación e incluso posibles datos. \n",
    "* Detectamos cuales son las variables categóricas y cuales las numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos estadísticas generales de los datos de training\n",
    "print(\"Estadísticas Generales de los Datos de Entrenamiento:\")\n",
    "display(df_train.describe(include='all').transpose())\n",
    "\n",
    "# identificamos variables categóricas y numéricas\n",
    "categorical_cols = df_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = df_train.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# printeamos las variables categóricas y numéricas\n",
    "print(\"\\nVariables Categóricas:\", categorical_cols)\n",
    "print(\"\\nVariables Numéricas:\", numerical_cols)\n",
    "\n",
    "\n",
    "# verificamos variación en las columnas de los datos de entrenamiento\n",
    "print(\"\\nVariación en Columnas de Datos de Entrenamiento:\")\n",
    "for col in df_train.columns:\n",
    "    unique_values = df_train[col].nunique()\n",
    "    print(f\"{col}: {unique_values} valores únicos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483c72dc",
   "metadata": {},
   "source": [
    "### Valores faltantes o nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc7d650",
   "metadata": {},
   "source": [
    "* Obtenemos el número de nulos existentes en los datasets\n",
    "* Si alguna columna presenta nulos, debemos saber como analizar según el tipo de variable y el contexto. Por ejemplo, si es numérica debemos reemplazar con 0 o el avg; si es categórica, podemos reemplazar el nulo con un dato significativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8132de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = df_train.isnull().sum().sort_values(ascending=False)\n",
    "missing_perc = (missing_counts / df_train.shape[0]) * 100\n",
    "\n",
    "df_missing = pd.DataFrame({\n",
    "    \"nulos\": missing_counts,\n",
    "    \"pct_nulos\": missing_perc.round(2)\n",
    "}).loc[missing_perc > 0]  # solo se muestran las columnas con > 0% nulos\n",
    "\n",
    "print(\"Columnas con valores faltantes:\")\n",
    "display(df_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b4e4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluamos el impacto de eliminar filas con nulos\n",
    "\n",
    "print(\"Cantidad total de filas:\", df_train.shape[0])\n",
    "print(\"Cantidad de filas sin ningún nulo:\", df_train.dropna().shape[0])\n",
    "print(\"Porcentaje de filas que conservarías:\", round(100 * df_train.dropna().shape[0] / df_train.shape[0], 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cd048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# según el resultado anterior, vemos que todas las filas del dataset tienen al menos un valor nulo, por lo que eliminar filas no es una opción viable. \n",
    "# si hacemos dropna() perderíamos todo el dataset.\n",
    "\n",
    "# vemos cuantos nulos hay por columna\n",
    "total_filas = df_train.shape[0]\n",
    "nulos_por_col = df_train.isnull().sum().sort_values(ascending=False)\n",
    "porcentaje_nulos = (nulos_por_col / total_filas)\n",
    "\n",
    "nulos_df = pd.DataFrame({\n",
    "    'Nulos': nulos_por_col,\n",
    "    'Porcentaje': porcentaje_nulos.round(2)\n",
    "})\n",
    "\n",
    "display(nulos_df.head(20))  # solo nos quedamos con las primeras 20 filas con nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32984d26",
   "metadata": {},
   "source": [
    "### Eliminación de columnas con muchos nulos (usando un umbral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d7cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "umbral_nulos = 0.8 ## preguntar!!\n",
    "\n",
    "# identificamos las columnas que superan el umbral de nulos\n",
    "cols_muchos_nulos = porcentaje_nulos[porcentaje_nulos > umbral_nulos].index.tolist()\n",
    "\n",
    "print(\"Columnas con más del % de nulos establecido (\", umbral_nulos*100, \"%):\")\n",
    "print(cols_muchos_nulos)\n",
    "\n",
    "# eliminamos las columnas con muchos nulos\n",
    "df_limpio = df_train.drop(columns=cols_muchos_nulos)\n",
    "\n",
    "print(\"\\nDataset reducido de forma que se eliminaron las columnas con muchos nulos:\")\n",
    "print(\"Forma original:\", df_train.shape)    \n",
    "print(\"Forma reducida:\", df_limpio.shape)\n",
    "\n",
    "###### chequeo ######\n",
    "\n",
    "# vemos el porcentaje total de celdas nulas en el dataset limpio\n",
    "display(df_limpio.isnull().mean().sort_values(ascending=True).head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fd387d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
